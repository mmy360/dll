下面是添加了“是否实现”列的表格：

| **实现** | **模型名称**          | **会议/年份**                      | **论文标题**                                                        | **作者**                                                         | **链接**                                                   | **关键贡献**                                                 |
|----------|----------------------|---------------------------------|-------------------------------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------|------------------------------------------------------------|
| ✅        | **LeNet-5**          | IEEE 1998                      | Gradient-Based Learning Applied to Document Recognition            | Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner           | [Link](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)  | 开创了使用卷积神经网络（CNN）进行手写数字识别。                |
| ✅        | **AlexNet**          | NeurIPS 2012                   | ImageNet Classification with Deep Convolutional Neural Networks    | Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton                 | [Link](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) | 在ImageNet竞赛中取得突破性成绩，大幅提高了分类准确性。             |
|          | **VGGNet**           | ICLR 2015                      | Very Deep Convolutional Networks for Large-Scale Image Recognition | Karen Simonyan, Andrew Zisserman                                  | [Link](https://arxiv.org/pdf/1409.1556.pdf)                 | 通过增加网络深度改进分类性能，引入了VGG架构。                    |
|          | **GoogLeNet (Inception V1)** | CVPR 2015               | Going Deeper with Convolutions                                     | Christian Szegedy, Wojciech Zaremba, Sergey Ioffe                | [Link](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf) | 引入了Inception模块，提高了计算效率和分类性能。                  |
| ✅        | **ResNet**           | CVPR 2016                      | Deep Residual Learning for Image Recognition                       | Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun                | [Link](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) | 通过残差连接解决深度网络中的梯度消失问题，提高了模型性能。            |
|          | **DenseNet**         | CVPR 2017                      | Densely Connected Convolutional Networks                           | Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger | [Link](https://arxiv.org/pdf/1608.06993.pdf)                | 引入了密集连接层，改善了梯度流和特征复用。                        |
|          | **MobileNet V2**     | CVPR 2018                      | MobileNetV2: Inverted Residuals and Linear Bottlenecks             | Mark Sandler, Andrew Howard, Menglong Zhu, Li Zhang, etc.        | [Link](https://arxiv.org/pdf/1801.04381.pdf)                | 通过线性瓶颈和倒置残差提高了移动应用的效率和性能。                 |
|          | **MobileNet V3**     | CVPR 2019                      | MobileNetV3: When Efficiency Meets Accuracy                        | Andrew G. Howard, Mark Sandler, Grace Chu, et al.                | [Link](https://arxiv.org/pdf/1905.02244.pdf)                | 通过优化提高了MobileNet架构的准确性和效率。                     |
|          | **EfficientNet**     | ICML 2019                      | EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks | Mingxing Tan, Quoc V. Le                                     | [Link](https://arxiv.org/pdf/1905.11946.pdf)                | 通过复合缩放方法提高了分类性能和计算效率。                       |
|          | **Vision Transformers (ViT)** | NeurIPS 2020          | An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale | Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov       | [Link](https://arxiv.org/pdf/2010.11929.pdf)                | 将transformer应用于图像分类任务，打破了传统CNN的限制。             |
|          | **Swin Transformer** | CVPR 2021                      | Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | Ze Liu, Yutong Lin, Yue Cao, Han Hu, and others            | [Link](https://arxiv.org/pdf/2103.14030.pdf)                | 通过使用平移窗口的层次结构Vision Transformer改进了精度和效率。         |

这个表格在前面添加了“实现”列，用来标记哪些模型已经被实现了。
